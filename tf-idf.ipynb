{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100960a-9cc4-42e4-8679-44aa51e8ae01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e4c2d-b1e4-463a-8eb8-1b18a6d6749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b616c19f-ef52-4dab-92fe-c51c3a02d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Item I1: ['I6', 'I2', 'I3', 'I4', 'I5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK resources (run this once)\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize('running')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans and preprocesses the text.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text) # Remove punctuation and numbers\n",
    "        tokens = text.split()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    return ''\n",
    "\n",
    "def get_content_based_recommendations_improved(item_id, tfidf_matrix, indices, data, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommends items similar to the given item based on preprocessed descriptions\n",
    "    using TF-IDF and cosine similarity.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        idx = indices[item_id]\n",
    "        similarity_scores = list(enumerate(cosine_similarity(tfidf_matrix[idx], tfidf_matrix)[0]))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similar_indices = [i[0] for i in similarity_scores[1:top_n+1]]\n",
    "        return data['Item_ID'].iloc[similar_indices].tolist()\n",
    "    except KeyError:\n",
    "        return f\"Item ID '{item_id}' not found in the dataset.\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('item_descriptions.csv')\n",
    "\n",
    "# Apply text preprocessing to the descriptions\n",
    "data['Cleaned_Description'] = data['Description'].apply(preprocess_text)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer() # Removed stop_words here as we handle them in preprocessing\n",
    "\n",
    "# Fit and transform the cleaned descriptions\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['Cleaned_Description'])\n",
    "\n",
    "# Calculate the cosine similarity between items\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Create a mapping of item ID to index\n",
    "indices = pd.Series(data.index, index=data['Item_ID']).drop_duplicates()\n",
    "\n",
    "# Example: Get recommendations for Item I1\n",
    "item_id_to_recommend = 'I1'\n",
    "recommendations = get_content_based_recommendations_improved(item_id_to_recommend, tfidf_matrix, indices, data)\n",
    "print(f\"Recommendations for Item {item_id_to_recommend}: {recommendations}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693df4a2-b148-49ea-8e5a-99541e3ad961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exciting sci-fi adventure in space with alien encounters and thrilling action.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1237140-b541-4729-8d6e-3c2a2b54adef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fast-paced action thriller with car chases and intense fight sequences.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Description[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f200c-ec78-46ad-aea6-d931b8635acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
